{"env_info": "sys.platform: linux\nPython: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2: NVIDIA GeForce GTX 1080 Ti\nCUDA_HOME: /usr/local/cuda-10.2\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.10.1+cu102\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.11.2+cu102\nOpenCV: 4.6.0\nMMCV: 1.4.4\nMMCV Compiler: GCC 5.4\nMMCV CUDA Compiler: not available\nMMSegmentation: 0.24.1+b0b89f0", "seed": null, "exp_name": "vit_b_16_split_0_512x512_20k_12_10.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 3e-05, "memory": 3513, "data_time": 0.01822, "decode.loss_mask_ce": 2.65008, "decode.acc_seg": 15.36226, "loss": 2.65008, "time": 0.57051}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 7e-05, "memory": 3513, "data_time": 0.00581, "decode.loss_mask_ce": 1.86213, "decode.acc_seg": 61.56855, "loss": 1.86213, "time": 0.57848}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.0001, "memory": 3513, "data_time": 0.00618, "decode.loss_mask_ce": 1.45389, "decode.acc_seg": 62.40702, "loss": 1.45389, "time": 0.58796}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00013, "memory": 3513, "data_time": 0.00591, "decode.loss_mask_ce": 1.20921, "decode.acc_seg": 65.7131, "loss": 1.20921, "time": 0.59444}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00016, "memory": 3513, "data_time": 0.00652, "decode.loss_mask_ce": 1.00387, "decode.acc_seg": 70.89622, "loss": 1.00387, "time": 0.59444}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.0002, "memory": 3513, "data_time": 0.00601, "decode.loss_mask_ce": 0.94566, "decode.acc_seg": 71.12265, "loss": 0.94566, "time": 0.59183}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00023, "memory": 3513, "data_time": 0.00619, "decode.loss_mask_ce": 0.85254, "decode.acc_seg": 72.98771, "loss": 0.85254, "time": 0.59421}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00026, "memory": 3513, "data_time": 0.00604, "decode.loss_mask_ce": 0.85778, "decode.acc_seg": 73.39244, "loss": 0.85778, "time": 0.59659}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.00029, "memory": 3513, "data_time": 0.00621, "decode.loss_mask_ce": 0.73662, "decode.acc_seg": 76.90956, "loss": 0.73662, "time": 0.59369}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.00033, "memory": 3513, "data_time": 0.0061, "decode.loss_mask_ce": 0.77368, "decode.acc_seg": 74.14846, "loss": 0.77368, "time": 0.5969}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.00036, "memory": 3513, "data_time": 0.00658, "decode.loss_mask_ce": 0.71061, "decode.acc_seg": 77.17446, "loss": 0.71061, "time": 0.59709}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.00039, "memory": 3513, "data_time": 0.00584, "decode.loss_mask_ce": 0.70373, "decode.acc_seg": 77.34417, "loss": 0.70373, "time": 0.59638}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.00042, "memory": 3513, "data_time": 0.00612, "decode.loss_mask_ce": 0.70041, "decode.acc_seg": 77.67641, "loss": 0.70041, "time": 0.59631}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.00045, "memory": 3513, "data_time": 0.00657, "decode.loss_mask_ce": 0.65241, "decode.acc_seg": 79.3187, "loss": 0.65241, "time": 0.59585}
{"mode": "train", "epoch": 1, "iter": 750, "lr": 0.00048, "memory": 3513, "data_time": 0.00633, "decode.loss_mask_ce": 0.66958, "decode.acc_seg": 78.01673, "loss": 0.66958, "time": 0.59587}
{"mode": "train", "epoch": 1, "iter": 800, "lr": 0.00051, "memory": 3513, "data_time": 0.00641, "decode.loss_mask_ce": 0.63469, "decode.acc_seg": 79.49948, "loss": 0.63469, "time": 0.59673}
{"mode": "train", "epoch": 1, "iter": 850, "lr": 0.00054, "memory": 3513, "data_time": 0.00659, "decode.loss_mask_ce": 0.63452, "decode.acc_seg": 79.67814, "loss": 0.63452, "time": 0.59705}
{"mode": "train", "epoch": 2, "iter": 900, "lr": 0.00058, "memory": 3513, "data_time": 0.05891, "decode.loss_mask_ce": 0.62056, "decode.acc_seg": 79.84025, "loss": 0.62056, "time": 0.64556}
